{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 470 :: Information Storage and Retrieval :: Texas A&M University :: Fall 2018\n",
    "\n",
    "\n",
    "# Homework 3 (and 4):  Recommenders\n",
    "\n",
    "### 100 points [10% of your final grade; that's double!]\n",
    "\n",
    "### Due: November 8, 2018\n",
    "\n",
    "*Goals of this homework:* Put your knowledge of recommenders to work. \n",
    "\n",
    "*Submission Instructions (Google Classroom):* To submit your homework, rename this notebook as  `lastname_firstinitial_hw#.ipynb`. For example, my homework submission would be: `caverlee_j_hw3.ipynb`. Submit this notebook via **Google Classroom**. Your IPython notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Movielens Data\n",
    "\n",
    "For this first part, we're going to use part of the Movielens 100k dataset. Prior to the Netflix Prize, the Movielens data was **the** most important collection of movie ratings.\n",
    "\n",
    "First off, we need to load the data (including u.user, u.item, and ua.base). Here, we provide you with some helper code to load the data using [Pandas](http://pandas.pydata.org/). Pandas is a nice package for Python data analytics.\n",
    "\n",
    "You may need to install pandas doing something like:\n",
    "\n",
    "`conda install --name cs470 pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the user data\n",
    "users_df = pd.read_csv('u.user', sep='|', names=['UserId', 'Age', 'Gender', 'Occupation', 'ZipCode'])\n",
    "\n",
    "# Load the movies data: we will only use movie id and title for this homework\n",
    "movies_df = pd.read_csv('u.item', sep='|', names=['MovieId', 'Title'], usecols=range(2), encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Load the ratings data: ignore the timestamps\n",
    "ratings_df = pd.read_csv('ua.base', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n",
    "\n",
    "# Working on three different data frames is a pain\n",
    "# Let us create a single dataset by \"joining\" these three data frames\n",
    "movie_ratings_df = pd.merge(movies_df, ratings_df)\n",
    "movielens_df = pd.merge(movie_ratings_df, users_df)\n",
    "\n",
    "movielens_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Let's find similar users [20 points]\n",
    "\n",
    "Before we get to the actual task of building our recommender, let's familiarize ourselves with the Movielens data.\n",
    "\n",
    "Pandas is really nice, since it let's us do simple aggregates. For example, we can find a specific user and take a look at that user's ratings. For example, for the user with user ID = 363, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = movielens_df.groupby('UserId')\n",
    "User363 = gb.get_group(363)\n",
    "#the information for the user\n",
    "User363[:1][[\"UserId\", \"Age\", \"Gender\",\"Occupation\", \"ZipCode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then we can see his first 10 ratings:\n",
    "User363[['Title', 'Rating']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balderdash! Everyone agrees that Toy Story should be rated 5! Oh well, there's no accounting for taste.\n",
    "\n",
    "Moving on, let's try our hand at finding similar users to this base user (user ID = 363). In each of the following, **find the top-10 most similar users** to this base user. You should use all of the user's ratings, not just the top-10 like we showed above. We're going to try different similarity methods and see what differences arise.\n",
    "\n",
    "You should implement each of these similar methods yourself! \n",
    "\n",
    "###     Top-10 Most Similar Users Using\n",
    "#### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences among these three similarity methods? Which one do you prefer, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: User-User Collaborative Filtering: Similarity-Based Ratings Prediction [20 points]\n",
    "\n",
    "Now let's estimate the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97) based on the similar users. Find the 10 nearest (most similiar by using Pearson) users who rated the movie \"Dances with Wolves (1990)\" and try different aggregate functions. Recall, there are many different ways to aggregate the ratings of the nearest neighbors. We'll try three popular methods:\n",
    "\n",
    "### Method 1: Average. \n",
    "The first is to simply average the ratings of the nearest neighbors:\n",
    "$r_{c,s} = \\frac{1}{N}\\sum_{c'\\in \\hat{C}}r_{c',s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Weighted Average 1. \n",
    "The second is to take a weighted average, where we weight more \"similar\" neighbors higher: $r_{c,s} = k\\sum_{c'\\in \\hat{C}}sim(c, c')\\times r_{c',s}$\n",
    "\n",
    "Choose a reasonable k so that r_{c,s} is between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Weighted Average 2. \n",
    "An alternative weighted average is to weight the differences between their ratings and their average rating (in essence to reward movies that are above the mean): $r_{c,s} = \\bar{r}_c + k\\sum_{c'\\in \\hat{C}}sim(c, c')\\times (r_{c',s} - \\bar{r}_{c'})$\n",
    "\n",
    "Choose a reasonable k so that r_{c,s} is between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Baseline Recommendation (Global) [20 points]\n",
    "\n",
    "OK, so far we've built the basics of a user-user collaborative filtering approach; that is, we take a user, find similar users and then aggregate their ratings. \n",
    "\n",
    "An alternative approach is to consider just basic statistics of the movies and users themselves. This is the essence of the \"baseline\" recommender we discussed in class:\n",
    "\n",
    "$b_{xi} = \\mu + b_x + b_i$\n",
    "\n",
    "where $b_{x,i}$ is the baseline estimate rating user x would give to item i, $\\mu$ is the overall mean rating, $b_x$ is a user bias term, and $b_i$ is an item bias term.\n",
    "\n",
    "For this part, let's once again estimate the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97), but this time using the baseline recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Local + Global Recommendation (Baseline + Item-Item CF) [20 points]\n",
    "\n",
    "Our final recommender combines the global baseline recommender with an item-item local recommender. \n",
    "\n",
    "$\\hat{r}_{xi} = b_{xi} + \\dfrac{\\sum_{j \\in N(i;x)}s_{ij} \\cdot (r_{xj} - b_{xj})}{\\sum_{j \\in N(i;x)}s_{ij}} $\n",
    "\n",
    "where \n",
    "* $\\hat{r}_{xi}$ is our estimated rating for what user x would give to item i.\n",
    "* $s_{ij}$ is the similarity of items i and j.\n",
    "* $r_{xj}$ is the rating of user x on item j.\n",
    "* $N(i;x)$ is the set of items similar to item i that were rated by x.\n",
    "\n",
    "You will need to make some design choices here about what similarity measure to use and what threshold to determine what items belong in $N(i;x)$.\n",
    "\n",
    "Now show us what this estimates the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97) to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Putting it all together! [20 points]\n",
    "\n",
    "Finally, we're going to experiment with our different methods to see which one performs the best on our special test set of \"hidden\" ratings. We have three big \"kinds\" of recommenders:\n",
    "\n",
    "* User-User Collaborative Filtering\n",
    "* Baseline Recommendation (Global)\n",
    "* Local + Global Recommender\n",
    "\n",
    "\n",
    "But within each, we have lots of design choices. For example, do we try Jaccard+Average or Jaccard+WeightedAverage1? Do we try Jaccard or Cosine or Pearson? What choice of k? Etc.\n",
    "\n",
    "For this part, you should train your methods on a special train set (the base set, see below). Then report your results over the test set (see below). You should use RMSE as your metric of choice. Which method performs best? You will need to experiment with many different approaches, but ultimately, you should tell us the best 2 or 3 methods and report the RMSE you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('ua.base', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n",
    "test = pd.read_csv('ua.test', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*provide your best 2 or 3 methods, their RMSE, plus some discussion of why they did the best*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: \n",
    "Can you do better? Find a way to improve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 470 :: Information Storage and Retrieval :: Texas A&M University :: Fall 2018\n",
    "\n",
    "\n",
    "# Homework 3 (and 4):  Recommenders\n",
    "\n",
    "### 100 points [10% of your final grade; that's double!]\n",
    "\n",
    "### Due: November 8, 2018\n",
    "\n",
    "*Goals of this homework:* Put your knowledge of recommenders to work. \n",
    "\n",
    "*Submission Instructions (Google Classroom):* To submit your homework, rename this notebook as  `lastname_firstinitial_hw#.ipynb`. For example, my homework submission would be: `caverlee_j_hw3.ipynb`. Submit this notebook via **Google Classroom**. Your IPython notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Movielens Data\n",
    "\n",
    "For this first part, we're going to use part of the Movielens 100k dataset. Prior to the Netflix Prize, the Movielens data was **the** most important collection of movie ratings.\n",
    "\n",
    "First off, we need to load the data (including u.user, u.item, and ua.base). Here, we provide you with some helper code to load the data using [Pandas](http://pandas.pydata.org/). Pandas is a nice package for Python data analytics.\n",
    "\n",
    "You may need to install pandas doing something like:\n",
    "\n",
    "`conda install --name cs470 pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Title</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieId              Title  UserId  Rating  Age Gender  Occupation ZipCode\n",
       "0        1   Toy Story (1995)       1       5   24      M  technician   85711\n",
       "1        2   GoldenEye (1995)       1       3   24      M  technician   85711\n",
       "2        3  Four Rooms (1995)       1       4   24      M  technician   85711\n",
       "3        4  Get Shorty (1995)       1       3   24      M  technician   85711\n",
       "4        5     Copycat (1995)       1       3   24      M  technician   85711"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call(['pip', 'install', 'pandas'])\n",
    "subprocess.call(['pip', 'install', 'numpy'])\n",
    "import pandas as pd\n",
    "from statistics import stdev\n",
    "import heapq\n",
    "import math\n",
    "\n",
    "# Load the user data\n",
    "users_df = pd.read_csv('u.user', sep='|', names=['UserId', 'Age', 'Gender', 'Occupation', 'ZipCode'])\n",
    "\n",
    "# Load the movies data: we will only use movie id and title for this homework\n",
    "movies_df = pd.read_csv('u.item', sep='|', names=['MovieId', 'Title'], usecols=range(2), encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Load the ratings data: ignore the timestamps\n",
    "ratings_df = pd.read_csv('ua.base', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n",
    "\n",
    "# Working on three different data frames is a pain\n",
    "# Let us create a single dataset by \"joining\" these three data frames\n",
    "movie_ratings_df = pd.merge(movies_df, ratings_df)\n",
    "movielens_df = pd.merge(movie_ratings_df, users_df)\n",
    "\n",
    "movielens_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Let's find similar users [20 points]\n",
    "\n",
    "Before we get to the actual task of building our recommender, let's familiarize ourselves with the Movielens data.\n",
    "\n",
    "Pandas is really nice, since it let's us do simple aggregates. For example, we can find a specific user and take a look at that user's ratings. For example, for the user with user ID = 363, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23594</th>\n",
       "      <td>363</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>87501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserId  Age Gender Occupation ZipCode\n",
       "23594     363   20      M    student   87501"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbu = movielens_df.groupby('UserId')\n",
    "gbm = movielens_df.groupby('MovieId')\n",
    "\n",
    "# Hacky little optimization (since dfs are slow and dicts are fast!)\n",
    "rat_du = {u:d.set_index('MovieId')['Rating'].to_dict() for u,d in gbu}\n",
    "rat_dm = {m:d.set_index('UserId')['Rating'].to_dict() for m,d in gbm}\n",
    "\n",
    "# Information for a user\n",
    "User363 = gbu.get_group(363)\n",
    "User363[:1][[\"UserId\", \"Age\", \"Gender\",\"Occupation\", \"ZipCode\"]]\n",
    "\n",
    "# Information for a movie\n",
    "#Movie97 = gbm.get_group(97)\n",
    "#Movie97[:1][[\"MovieId\", \"Title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23594</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23595</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23596</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23597</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23598</th>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23600</th>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23601</th>\n",
       "      <td>Seven (Se7en) (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23602</th>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23603</th>\n",
       "      <td>From Dusk Till Dawn (1996)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating\n",
       "23594            Toy Story (1995)       2\n",
       "23595            GoldenEye (1995)       4\n",
       "23596           Get Shorty (1995)       5\n",
       "23597              Copycat (1995)       1\n",
       "23598       Twelve Monkeys (1995)       3\n",
       "23599                 Babe (1995)       5\n",
       "23600     Dead Man Walking (1995)       3\n",
       "23601        Seven (Se7en) (1995)       5\n",
       "23602  Usual Suspects, The (1995)       5\n",
       "23603  From Dusk Till Dawn (1996)       4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then we can see his first 10 ratings:\n",
    "User363[['Title', 'Rating']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balderdash! Everyone agrees that Toy Story should be rated 5! Oh well, there's no accounting for taste.\n",
    "\n",
    "Moving on, let's try our hand at finding similar users to this base user (user ID = 363). In each of the following, **find the top-10 most similar users** to this base user. You should use all of the user's ratings, not just the top-10 like we showed above. We're going to try different similarity methods and see what differences arise.\n",
    "\n",
    "You should implement each of these similar methods yourself! \n",
    "\n",
    "###     Top-10 Most Similar Users Using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas = {\n",
    "    #'basic_jaccard': lambda x, y: diff(x, y)/union(x, y),\n",
    "    #'jaccard': lambda x, y: w_diff(x, y)/w_union(x, y),\n",
    "    #'cosine': lambda x, y: dot_prod(x, y)/(magn(x)*magn(y)),\n",
    "    #'pearson': lambda x, y: covariance(x, y)/std_wrt(x, y),\n",
    "    'default': lambda x, y: len(x.keys()&y.keys())/len(x.keys()|y.keys())\n",
    "}\n",
    "data_types = {\n",
    "    'user': {\n",
    "        'gb': gbu,\n",
    "        'data': lambda id: gbu.get_group(id)[['MovieId','Rating']],\n",
    "        'rats': lambda dat: dat.set_index('MovieId')['Rating'].to_dict(),\n",
    "        'rat2': lambda id: rat_du[id]\n",
    "    },\n",
    "    'movie': {\n",
    "        'gb': gbm,\n",
    "        'data': lambda id: gbm.get_group(id)[['UserId','Rating']],\n",
    "        'rats': lambda dat: dat.set_index('UserId')['Rating'].to_dict(),\n",
    "        'rat2': lambda id: rat_dm[id]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fetch top-X most similar users/items; 'method' arg used to select approach\n",
    "def most_similar(my_id, type='user', method='default', request=10):\n",
    "    # Pull ratings for the input user/item\n",
    "    #my_data = data_types[type]['data'](my_id)\n",
    "    my_rats = data_types[type]['rat2'](my_id)\n",
    "\n",
    "    heap = [] # size limited by max 'request' arg\n",
    "    for ur_id,ur_data in data_types[type]['gb']:\n",
    "        if ur_id == my_id: continue\n",
    "\n",
    "        # Pull ratings for this user/item and compute score\n",
    "        ur_rats = data_types[type]['rat2'](ur_id)\n",
    "        score = formulas[method](my_rats, ur_rats)\n",
    "        # Store similarity score and userId in heap\n",
    "        if len(heap) < request: heapq.heappush(heap, (score, ur_id))\n",
    "        elif score > heap[0][0]: heapq.heappushpop(heap, (score, ur_id))\n",
    "    heap.sort(reverse=True)\n",
    "    return heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278445006 - user:276\n",
      "0.262081784 - user:293\n",
      "0.261770245 - user:435\n",
      "0.256660746 - user:301\n",
      "0.254002134 - user:429\n",
      "0.253692762 - user:092\n",
      "0.252059308 - user:916\n",
      "0.251931994 - user:561\n",
      "0.250000000 - user:268\n",
      "0.249521623 - user:896\n"
     ]
    }
   ],
   "source": [
    "# Boring regular union and intersection (currently unused code)\n",
    "def union(rat1, rat2):\n",
    "    return len(rat1) + sum(0 if m in rat1 else 1 for m in rat2)\n",
    "def diff(rat1, rat2):\n",
    "    return sum(1 if m in rat1 else 0 for m in rat2)\n",
    "\n",
    "# Set union and intersection, weighted by rating distance (for Bonus problem)\n",
    "def w_union(rat1, rat2):\n",
    "    return len(rat1) + sum(0.2*abs(rat1.get(m, rat2[m]-5) - rat2[m]) for m in rat2)\n",
    "def w_diff(rat1, rat2):\n",
    "    return sum(1 - 0.2*abs(rat1.get(m, rat2[m]+5) - rat2[m]) for m in rat2)\n",
    "\n",
    "formulas['jaccard'] = lambda x, y: w_diff(x, y)/w_union(x, y)\n",
    "\n",
    "for u in most_similar(363, method='jaccard'):\n",
    "    print(\"{:.9f} - user:{:03}\".format(u[0], u[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603857486 - user:276\n",
      "0.530818760 - user:864\n",
      "0.529114652 - user:435\n",
      "0.522761738 - user:303\n",
      "0.522502505 - user:429\n",
      "0.518805777 - user:896\n",
      "0.512385644 - user:092\n",
      "0.511879910 - user:682\n",
      "0.510761576 - user:497\n",
      "0.510252840 - user:222\n"
     ]
    }
   ],
   "source": [
    "def dot_prod(rat1, rat2):\n",
    "    return sum(rat1.get(m, 0)*rat2[m] for m in rat2)\n",
    "\n",
    "def magn(rat):\n",
    "    return math.sqrt(sum(rat[m]**2 for m in rat))\n",
    "\n",
    "formulas['cosine'] = lambda x, y: dot_prod(x, y)/(magn(x)*magn(y))\n",
    "\n",
    "for u in most_similar(363, method='cosine'):\n",
    "    print(\"{:.9f} - user:{:03}\".format(u[0], u[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.269867397 - user:276\n",
      "0.208027127 - user:889\n",
      "0.204050740 - user:092\n",
      "0.197552792 - user:293\n",
      "0.190429526 - user:435\n",
      "0.182419957 - user:758\n",
      "0.179706735 - user:007\n",
      "0.179420224 - user:268\n",
      "0.176710693 - user:013\n",
      "0.171415983 - user:643\n"
     ]
    }
   ],
   "source": [
    "def std_wrt(rat1, rat2):\n",
    "    if min(len(rat1), len(rat2)) < 2: return 1\n",
    "    stdevs12 = stdev(rat1.values())*stdev(rat2.values())\n",
    "    return 1 if stdevs12 == 0 else stdevs12\n",
    "\n",
    "def covariance(rat1, rat2):\n",
    "    m1 = sum(rat1.values())/len(rat1)\n",
    "    m2 = sum(rat2.values())/len(rat2)\n",
    "    return sum((rat1.get(m,m1) - m1)*(rat2[m] - m2) for m in rat2)/len(rat1)\n",
    "\n",
    "formulas['pearson'] = lambda x, y: covariance(x, y)/std_wrt(x, y)\n",
    "\n",
    "for u in most_similar(363, method='pearson'):\n",
    "    print(\"{:.9f} - user:{:03}\".format(u[0], u[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences among these three similarity methods? Which one do you prefer, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Jaccard is good at identifying users with similar watch lists, but the default implementation doesn't take actual rating scores into consideration, meaning despite being useful for finding users who have seen the same movies, those users may have very different dispositions when it comes to those movies. The Cosine similarity calculation effectively measures the difference in vector-angle between two users' ratings, meaning it will be a better indicator than Jaccard for finding users with similar preferences. However, Cosine is overly impacted by user bias or \"shifts\". What I mean by that is that not all users rate movies within the same range, some tend towards a higher mean rating while others tend towards a lower mean. Variations in different users' standard deviation of ratings can also impact Cosine similarity index to favor some users more than others. This is where Pearson similarity can improve the results by centering each user's ratings on their mean and dividing my their standard deviation.  This makes users with different rating biases much more comparable.<br>\n",
    "My preferred method is Jaccard, primarily due to its simplicity and algorithmic efficiency. All of the methods used here run in easily under a second, but the standard implementations of Cosine and Pearson involve the use of a square root function, which is computationally costly.  Jaccard can also be adjusted to respect differences in ratings while still maintaining its superior time complexity, which is actually something I did in my implementation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: User-User Collaborative Filtering: Similarity-Based Ratings Prediction [20 points]\n",
    "\n",
    "Now let's estimate the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97) based on the similar users. Find the 10 nearest (most similiar by using Pearson) users who rated the movie \"Dances with Wolves (1990)\" and try different aggregate functions. Recall, there are many different ways to aggregate the ratings of the nearest neighbors. We'll try three popular methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.269867397 - user:276 - r:3\n",
      "0.208027127 - user:889 - r:3\n",
      "0.197552792 - user:293 - r:4\n",
      "0.179706735 - user:007 - r:5\n",
      "0.179420224 - user:268 - r:4\n",
      "0.176710693 - user:013 - r:4\n",
      "0.164794341 - user:001 - r:3\n",
      "0.161367769 - user:429 - r:4\n",
      "0.161149605 - user:880 - r:4\n",
      "0.157990943 - user:561 - r:3\n"
     ]
    }
   ],
   "source": [
    "# Helper function to get a user's rating for a given movie\n",
    "def get_rat(uid, movie_id):\n",
    "    data = gbu.get_group(uid)\n",
    "    return list(data.loc[data['MovieId'] == movie_id, 'Rating'])\n",
    "\n",
    "def similar_who_rated(u_id, m_id, method='pearson', top=10, mult=30):\n",
    "    # Find x*mult nearest users using Pearson\n",
    "    similar = most_similar(u_id, method=method, request=top*mult)\n",
    "    # Trim to top x that have seen the movie with ID 'm_id'\n",
    "    return [(s,u,get_rat(u, m_id)[0]) for (s,u) in similar if get_rat(u, m_id)][:top]\n",
    "\n",
    "# UserId=363 @ \"Dances with Wolves\" (MovieId=97)\n",
    "sim_rat = similar_who_rated(363, 97)\n",
    "for u in sim_rat:\n",
    "    print(\"{:.9f} - user:{:03} - r:{}\".format(u[0], u[1], u[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Average. \n",
    "The first is to simply average the ratings of the nearest neighbors:\n",
    "$r_{c,s} = \\frac{1}{N}\\sum_{c'\\in \\hat{C}}r_{c',s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n"
     ]
    }
   ],
   "source": [
    "def pred_simple_avg(sim_rat):\n",
    "    # Simple average of similar users' ratings\n",
    "    return sum(r for (s,u,r) in sim_rat)/len(sim_rat)\n",
    "\n",
    "print(pred_simple_avg(sim_rat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Weighted Average 1. \n",
    "The second is to take a weighted average, where we weight more \"similar\" neighbors higher: $r_{c,s} = k\\sum_{c'\\in \\hat{C}}sim(c, c')\\times r_{c',s}$\n",
    "\n",
    "Choose a reasonable k so that r_{c,s} is between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6655298870774486\n"
     ]
    }
   ],
   "source": [
    "def pred_weight_avg(sim_rat):\n",
    "    # k = 1/sum(similarity of compared users)\n",
    "    return sum(r*s for (s,u,r) in sim_rat)/sum(s for (s,u,r) in sim_rat)\n",
    "\n",
    "print(pred_weight_avg(sim_rat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Weighted Average 2. \n",
    "An alternative weighted average is to weight the differences between their ratings and their average rating (in essence to reward movies that are above the mean): $r_{c,s} = \\bar{r}_c + k\\sum_{c'\\in \\hat{C}}sim(c, c')\\times (r_{c',s} - \\bar{r}_{c'})$\n",
    "\n",
    "Choose a reasonable k so that r_{c,s} is between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.375631881236712\n"
     ]
    }
   ],
   "source": [
    "def get_mean(user_id):\n",
    "    user_data = data_types['user']['data'](user_id)\n",
    "    user_rats = data_types['user']['rats'](user_data)\n",
    "    return sum(user_rats.values())/len(user_rats)\n",
    "\n",
    "def pred_weight_avg2(user_id, sim_rat):\n",
    "    return get_mean(user_id) + \\\n",
    "    sum(s*(r - get_mean(u)) for (s,u,r) in sim_rat)/sum(s for (s,u,r) in sim_rat)\n",
    "\n",
    "print(pred_weight_avg2(363, sim_rat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Baseline Recommendation (Global) [20 points]\n",
    "\n",
    "OK, so far we've built the basics of a user-user collaborative filtering approach; that is, we take a user, find similar users and then aggregate their ratings. \n",
    "\n",
    "An alternative approach is to consider just basic statistics of the movies and users themselves. This is the essence of the \"baseline\" recommender we discussed in class:\n",
    "\n",
    "$b_{xi} = \\mu + b_x + b_i$\n",
    "\n",
    "where $b_{x,i}$ is the baseline estimate rating user x would give to item i, $\\mu$ is the overall mean rating, $b_x$ is a user bias term, and $b_i$ is an item bias term.\n",
    "\n",
    "For this part, let's once again estimate the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97), but this time using the baseline recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.5238268742409184\n",
      "User bias: -0.47067072806151655\n",
      "Item bias: 0.2515968545726408\n",
      "Prediction: 3.3047530007520427\n"
     ]
    }
   ],
   "source": [
    "# Mu (overall mean rating)\n",
    "mu = sum(ratings_df['Rating'])/len(ratings_df['Rating'])\n",
    "user_bias = {u:(sum(d['Rating'])/len(d['Rating'])) - mu for u,d in gbu}\n",
    "item_bias = {m:(sum(d['Rating'])/len(d['Rating'])) - mu for m,d in gbm}\n",
    "\n",
    "def pred_bxi(u, i):\n",
    "    return mu + user_bias[u] + item_bias[i]\n",
    "\n",
    "bxi = pred_bxi(363, 97)\n",
    "print(\"Mean:\", mu)\n",
    "print(\"User bias:\", user_bias[363])\n",
    "print(\"Item bias:\", item_bias[97])\n",
    "print(\"Prediction:\", bxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Local + Global Recommendation (Baseline + Item-Item CF) [20 points]\n",
    "\n",
    "Our final recommender combines the global baseline recommender with an item-item local recommender. \n",
    "\n",
    "$\\hat{r}_{xi} = b_{xi} + \\dfrac{\\sum_{j \\in N(i;x)}s_{ij} \\cdot (r_{xj} - b_{xj})}{\\sum_{j \\in N(i;x)}s_{ij}} $\n",
    "\n",
    "where \n",
    "* $\\hat{r}_{xi}$ is our estimated rating for what user x would give to item i.\n",
    "* $s_{ij}$ is the similarity of items i and j.\n",
    "* $r_{xj}$ is the rating of user x on item j.\n",
    "* $N(i;x)$ is the set of items similar to item i that were rated by x.\n",
    "\n",
    "You will need to make some design choices here about what similarity measure to use and what threshold to determine what items belong in $N(i;x)$.\n",
    "\n",
    "Now show us what this estimates the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97) to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 3.121941439082882\n"
     ]
    }
   ],
   "source": [
    "# Baseline + Item-Item Collaborative Filtering\n",
    "def pred_global(u, i, method='pearson', N=50):\n",
    "    # Fetch similar movies using pearson correlation\n",
    "    similar = most_similar(i, 'movie', method, N)\n",
    "    sim_rat = [(s,i,get_rat(u, i)[0]) for (s,i) in similar if get_rat(u, i)]\n",
    "    rxi = bxi\n",
    "    rxi += sum(s*(r - pred_bxi(u, i)) for (s,i,r) in sim_rat)/sum(s for (s,i,r) in sim_rat)\n",
    "    return min(max(rxi, 1), 5)\n",
    "\n",
    "rxi = pred_global(363, 97)\n",
    "print(\"Predicted:\", rxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Putting it all together! [20 points]\n",
    "\n",
    "Finally, we're going to experiment with our different methods to see which one performs the best on our special test set of \"hidden\" ratings. We have three big \"kinds\" of recommenders:\n",
    "\n",
    "* User-User Collaborative Filtering\n",
    "* Baseline Recommendation (Global)\n",
    "* Local + Global Recommender\n",
    "\n",
    "\n",
    "But within each, we have lots of design choices. For example, do we try Jaccard+Average or Jaccard+WeightedAverage1? Do we try Jaccard or Cosine or Pearson? What choice of k? Etc.\n",
    "\n",
    "For this part, you should train your methods on a special train set (the base set, see below). Then report your results over the test set (see below). You should use RMSE as your metric of choice. Which method performs best? You will need to experiment with many different approaches, but ultimately, you should tell us the best 2 or 3 methods and report the RMSE you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataframe\n",
    "train = pd.read_csv('ua.base',sep='\\t',names=['UserId','MovieId','Rating'],usecols=range(3))\n",
    "gbu = train.groupby('UserId')\n",
    "gbm = train.groupby('MovieId')\n",
    "# Load testing dataframe\n",
    "test = pd.read_csv('ua.test',sep='\\t',names=['UserId','MovieId','Rating'],usecols=range(3))\n",
    "gbu_t = test.groupby('UserId')\n",
    "gbm_t = test.groupby('MovieId')\n",
    "\n",
    "# Compute training Mu (overall mean rating) and item/user biases\n",
    "mu = sum(train['Rating'])/len(train['Rating'])\n",
    "user_bias = {u:(sum(d['Rating'])/len(d['Rating'])) - mu for u,d in gbu}\n",
    "item_bias = {m:(sum(d['Rating'])/len(d['Rating'])) - mu for m,d in gbm}\n",
    "\n",
    "# User-Rating map for faster lookup\n",
    "rat_dm = {m:d.set_index('UserId')['Rating'].to_dict() for m,d in gbm}\n",
    "rat_du = {u:d.set_index('MovieId')['Rating'].to_dict() for u,d in gbu}\n",
    "rat_du_t = {u:d.set_index('MovieId')['Rating'].to_dict() for u,d in gbu_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.8710160064409769\n",
      "Cosine + Simple Avg: 0.9822616161965515\n",
      "Jaccard + Avg Weighted 2: 0.9196408457097335\n"
     ]
    }
   ],
   "source": [
    "pred_types = {\n",
    "    'avg': lambda s, u, i: pred_simple_avg(s),\n",
    "    'avg_w': lambda s, u, i: pred_weight_avg(s),\n",
    "    'avg_w2': lambda s, u, i: pred_weight_avg2(u, s),\n",
    "    'baseline': lambda s, u, i: pred_bxi(u, i),\n",
    "    'global': lambda s, u, i: pred_global(u, i)\n",
    "}\n",
    "\n",
    "def pred_rmse(method='jaccard', predict='baseline', N=10, cut=10):\n",
    "    offsets = []\n",
    "    for u_id,u_data in gbu:\n",
    "        if u_id > cut: break\n",
    "        if len(rat_du_t[u_id]) == 0: continue # No test data for this user\n",
    "        u_sim = most_similar(u_id, method=method, request=N*30)\n",
    "        for m_id in rat_du_t[u_id]:\n",
    "            if m_id not in item_bias: continue # No test data for this movie\n",
    "            sim_rat = [(s,u,rat_du[u][m_id]) for (s,u) in u_sim if m_id in rat_du[u]][:N]\n",
    "            pred_score = pred_types[predict](sim_rat, u_id, m_id)\n",
    "            error = rat_du_t[u_id][m_id] - pred_score\n",
    "            offsets.append(error)\n",
    "    rmse = math.sqrt(sum(x**2 for x in offsets)/len(offsets))\n",
    "    return rmse\n",
    "\n",
    "print(\"Baseline:\", pred_rmse('jaccard', 'baseline'))\n",
    "print(\"Cosine + Simple Avg:\", pred_rmse('pearson', 'avg'))\n",
    "print(\"Jaccard + Avg Weighted 2:\", pred_rmse('jaccard', 'avg_w2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*provide your best 2 or 3 methods, their RMSE, plus some discussion of why they did the best*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, baseline recommendation seemed to work the best on the test data. This could either be because the sample size is very small (only 943 users) or because I made some error in my calculations some where. However, this are similar numbers to what other people got on Piazza so lol maybe it's fine after all.  My custom-weighted Jaccard outperformed cosine both with and without using simple or weighted averages. I think these results did best because they are simple yet broad in consideration of users' preferences, and tend to match users will on smaller amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: \n",
    "Can you do better? Find a way to improve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made a modification to Jaccard that essentials weights union/intersection based on ratings\n",
    "# Given {MovieId:Rating,...}, union of {1:5},{2:4} is still =2.0, and union of {1:5},{1:5} is\n",
    "# still =1.0, but union of {1:5},{1:4}=0.2, {1:5},{1:3}=0.4, {1:5,1:2}=0.6, and {1:5,1:1}=0.8\n",
    "# Similar (but inverse) for intersection. I've already made the Jaccard improvement, and the\n",
    "# RMSE improvement is around ~0.06 over regular Jaccard, which I think seems pretty good :)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
